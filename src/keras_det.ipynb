{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "save_path=\"../data/models/\"\n",
    "model_name=\"first_try.h5\"\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 32\n",
    "\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/test'\n",
    "nb_train_samples = 100\n",
    "nb_validation_samples = 40\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 images belonging to 2 classes.\n",
      "Found 412 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 5.2907 - accuracy: 0.5595 - val_loss: 0.0661 - val_accuracy: 0.9375\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.4380 - accuracy: 0.6979 - val_loss: 0.2898 - val_accuracy: 0.9375\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.7507 - accuracy: 0.6771 - val_loss: 1.6406 - val_accuracy: 0.5312\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.6926 - accuracy: 0.7188 - val_loss: 0.6240 - val_accuracy: 0.8750\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.7632 - accuracy: 0.6771 - val_loss: 0.5328 - val_accuracy: 0.6562\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.6939 - accuracy: 0.6562 - val_loss: 0.3764 - val_accuracy: 0.8438\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5297 - accuracy: 0.7143 - val_loss: 0.5617 - val_accuracy: 0.6562\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.4098 - accuracy: 0.7738 - val_loss: 0.3011 - val_accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4851 - accuracy: 0.8021 - val_loss: 0.7301 - val_accuracy: 0.9375\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6749 - accuracy: 0.7604 - val_loss: 0.3113 - val_accuracy: 0.9062\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4937 - accuracy: 0.7396 - val_loss: 0.7243 - val_accuracy: 0.7812\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.3949 - val_accuracy: 0.9062\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.5516 - accuracy: 0.7857 - val_loss: 0.9141 - val_accuracy: 0.7857\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.5072 - accuracy: 0.7262 - val_loss: 0.3304 - val_accuracy: 0.9062\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.3358 - val_accuracy: 0.9062\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3858 - accuracy: 0.8438 - val_loss: 0.4114 - val_accuracy: 0.9375\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.4880 - accuracy: 0.8095 - val_loss: 0.6691 - val_accuracy: 0.6562\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.3146 - val_accuracy: 0.9375\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.5476 - accuracy: 0.8229 - val_loss: 0.3741 - val_accuracy: 0.9062\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.9453 - accuracy: 0.7024 - val_loss: 0.2195 - val_accuracy: 0.9062\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4054 - accuracy: 0.7917 - val_loss: 0.3731 - val_accuracy: 0.7812\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3872 - accuracy: 0.8646 - val_loss: 0.8920 - val_accuracy: 0.2500\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.4434 - accuracy: 0.8542 - val_loss: 0.8508 - val_accuracy: 0.8750\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.3271 - accuracy: 0.8690 - val_loss: 0.3058 - val_accuracy: 0.9062\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.4352 - accuracy: 0.8125 - val_loss: 0.3234 - val_accuracy: 0.9375\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.4224 - accuracy: 0.8438 - val_loss: 0.3580 - val_accuracy: 0.9286\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.3563 - accuracy: 0.8333 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.7131 - accuracy: 0.8125 - val_loss: 0.3847 - val_accuracy: 0.9375\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.3380 - accuracy: 0.8646 - val_loss: 0.6201 - val_accuracy: 0.7812\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3494 - accuracy: 0.8542 - val_loss: 0.7262 - val_accuracy: 0.8125\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.4216 - accuracy: 0.8214 - val_loss: 0.2392 - val_accuracy: 0.9375\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2642 - accuracy: 0.9062 - val_loss: 0.2142 - val_accuracy: 0.8750\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.4646 - accuracy: 0.8571 - val_loss: 0.9236 - val_accuracy: 0.6875\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3360 - accuracy: 0.8854 - val_loss: 0.4145 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2935 - accuracy: 0.8750 - val_loss: 0.9020 - val_accuracy: 0.8750\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4494 - accuracy: 0.8542 - val_loss: 0.2849 - val_accuracy: 0.9688\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3718 - accuracy: 0.8438 - val_loss: 0.9250 - val_accuracy: 0.8438\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5375 - accuracy: 0.8571 - val_loss: 0.2306 - val_accuracy: 0.8750\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.6246 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.8571\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3308 - accuracy: 0.8750 - val_loss: 0.3692 - val_accuracy: 0.9062\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4041 - accuracy: 0.8958 - val_loss: 0.0817 - val_accuracy: 0.9688\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.2652 - accuracy: 0.9167 - val_loss: 0.6153 - val_accuracy: 0.8750\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.2740 - accuracy: 0.8750 - val_loss: 0.7502 - val_accuracy: 0.8750\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5243 - accuracy: 0.7976 - val_loss: 0.2768 - val_accuracy: 0.9062\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.2760 - accuracy: 0.8854 - val_loss: 0.7691 - val_accuracy: 0.8125\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3823 - accuracy: 0.9167 - val_loss: 0.2503 - val_accuracy: 0.9375\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.3596 - accuracy: 0.8214 - val_loss: 0.8310 - val_accuracy: 0.8125\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3141 - accuracy: 0.9048 - val_loss: 0.0957 - val_accuracy: 0.9688\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.2144 - accuracy: 0.9271 - val_loss: 0.1451 - val_accuracy: 0.9688\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.4966 - accuracy: 0.8125 - val_loss: 0.4642 - val_accuracy: 0.7812\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3056 - accuracy: 0.8958 - val_loss: 0.6737 - val_accuracy: 0.8125\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2156 - accuracy: 0.9286 - val_loss: 0.8854 - val_accuracy: 0.8929\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3588 - accuracy: 0.8750 - val_loss: 0.3077 - val_accuracy: 0.8438\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3357 - accuracy: 0.8646 - val_loss: 0.8453 - val_accuracy: 0.8125\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.4555 - accuracy: 0.7500 - val_loss: 0.2216 - val_accuracy: 0.9688\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.2943 - accuracy: 0.9062 - val_loss: 0.5177 - val_accuracy: 0.7812\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5524 - accuracy: 0.8333 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 59ms/step - loss: 0.2858 - accuracy: 0.8958 - val_loss: 0.2414 - val_accuracy: 0.8438\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5409 - accuracy: 0.8452 - val_loss: 0.4794 - val_accuracy: 0.9062\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2602 - accuracy: 0.8854 - val_loss: 0.2383 - val_accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3692 - accuracy: 0.8438 - val_loss: 0.8538 - val_accuracy: 0.8125\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.2797 - accuracy: 0.8750 - val_loss: 0.6875 - val_accuracy: 0.8438\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.3200 - accuracy: 0.8929 - val_loss: 0.6901 - val_accuracy: 0.9375\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2105 - accuracy: 0.9375 - val_loss: 0.6114 - val_accuracy: 0.9062\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1986 - accuracy: 0.9375 - val_loss: 0.1371 - val_accuracy: 0.8929\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.3906 - accuracy: 0.9048 - val_loss: 1.6848 - val_accuracy: 0.5938\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.3749 - accuracy: 0.8646 - val_loss: 0.5068 - val_accuracy: 0.9062\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2560 - accuracy: 0.8958 - val_loss: 0.0814 - val_accuracy: 0.9688\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2606 - accuracy: 0.9062 - val_loss: 1.1716 - val_accuracy: 0.9062\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.4138 - accuracy: 0.8571 - val_loss: 0.4021 - val_accuracy: 0.9375\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3366 - accuracy: 0.8750 - val_loss: 0.1946 - val_accuracy: 0.9375\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1881 - accuracy: 0.9048 - val_loss: 0.2108 - val_accuracy: 0.9062\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.4309 - accuracy: 0.8333 - val_loss: 0.2875 - val_accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3046 - accuracy: 0.8646 - val_loss: 0.5915 - val_accuracy: 0.8125\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3416 - accuracy: 0.8646 - val_loss: 0.1603 - val_accuracy: 0.9375\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2631 - accuracy: 0.9048 - val_loss: 0.1754 - val_accuracy: 0.8750\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.2483 - accuracy: 0.8854 - val_loss: 0.3496 - val_accuracy: 0.8750\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.2988 - accuracy: 0.8750 - val_loss: 0.1091 - val_accuracy: 0.8214\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.2771 - accuracy: 0.9048 - val_loss: 0.3330 - val_accuracy: 0.8750\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3051 - accuracy: 0.9048 - val_loss: 0.7938 - val_accuracy: 0.8438\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3709 - accuracy: 0.9167 - val_loss: 0.1383 - val_accuracy: 0.9688\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1609 - accuracy: 0.9375 - val_loss: 0.1551 - val_accuracy: 0.9688\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.3071 - accuracy: 0.9048 - val_loss: 0.1514 - val_accuracy: 0.9375\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3139 - accuracy: 0.8646 - val_loss: 0.0046 - val_accuracy: 0.9375\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3531 - accuracy: 0.9479 - val_loss: 0.1284 - val_accuracy: 0.9062\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.3150 - accuracy: 0.8452 - val_loss: 0.5524 - val_accuracy: 0.8125\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.2069 - accuracy: 0.9167 - val_loss: 0.3091 - val_accuracy: 0.9062\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.2933 - accuracy: 0.9167 - val_loss: 0.7970 - val_accuracy: 0.8438\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.2407 - accuracy: 0.9167 - val_loss: 0.6341 - val_accuracy: 0.8125\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.2574 - accuracy: 0.9286 - val_loss: 1.4320 - val_accuracy: 0.8750\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3561 - accuracy: 0.8646 - val_loss: 0.0579 - val_accuracy: 0.9286\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.2570 - accuracy: 0.9062 - val_loss: 0.2166 - val_accuracy: 0.8750\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.4534 - accuracy: 0.8452 - val_loss: 0.3256 - val_accuracy: 0.9062\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2461 - accuracy: 0.9375 - val_loss: 0.4201 - val_accuracy: 0.8750\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2299 - accuracy: 0.9167 - val_loss: 0.0057 - val_accuracy: 0.9062\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.2768 - accuracy: 0.9062 - val_loss: 0.7437 - val_accuracy: 0.8750\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.3188 - accuracy: 0.9167 - val_loss: 0.1950 - val_accuracy: 0.9375\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2931 - accuracy: 0.8854 - val_loss: 0.3631 - val_accuracy: 0.9375\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1517 - accuracy: 0.9286 - val_loss: 0.7345 - val_accuracy: 0.8750\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1586 - accuracy: 0.9271 - val_loss: 0.6751 - val_accuracy: 0.9062\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2738 - accuracy: 0.8646 - val_loss: 2.0267 - val_accuracy: 0.8438\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.2201 - accuracy: 0.9375 - val_loss: 2.1282 - val_accuracy: 0.7188\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.2656 - accuracy: 0.9167 - val_loss: 0.9837 - val_accuracy: 0.8438\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1976 - accuracy: 0.9271 - val_loss: 0.1965 - val_accuracy: 0.9286\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6364 - accuracy: 0.8571 - val_loss: 0.1996 - val_accuracy: 0.9062\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.3584 - accuracy: 0.8452 - val_loss: 0.1878 - val_accuracy: 0.9375\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2066 - accuracy: 0.9271 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.2325 - accuracy: 0.9167 - val_loss: 0.3651 - val_accuracy: 0.8125\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1190 - accuracy: 0.9688 - val_loss: 0.3584 - val_accuracy: 0.9375\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.2551 - accuracy: 0.8810 - val_loss: 1.0385 - val_accuracy: 0.8750\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.2329 - accuracy: 0.9271 - val_loss: 0.9235 - val_accuracy: 0.9062\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.3853 - accuracy: 0.9048 - val_loss: 0.3519 - val_accuracy: 0.8438\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2427 - accuracy: 0.9167 - val_loss: 0.2407 - val_accuracy: 0.9375\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2663 - accuracy: 0.9062 - val_loss: 0.4979 - val_accuracy: 0.9375\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.2334 - accuracy: 0.8929 - val_loss: 0.3163 - val_accuracy: 0.8438\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3889 - accuracy: 0.8542 - val_loss: 0.6632 - val_accuracy: 0.9375\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3886 - accuracy: 0.8854 - val_loss: 0.2866 - val_accuracy: 0.8929\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2445 - accuracy: 0.9271 - val_loss: 0.3682 - val_accuracy: 0.8438\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1088 - accuracy: 0.9479 - val_loss: 0.2809 - val_accuracy: 0.8750\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1386 - accuracy: 0.9286 - val_loss: 0.0873 - val_accuracy: 0.9375\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3569 - accuracy: 0.8854 - val_loss: 0.3743 - val_accuracy: 0.8438\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.3116 - accuracy: 0.8810 - val_loss: 0.2014 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2125 - accuracy: 0.8750 - val_loss: 0.5481 - val_accuracy: 0.9375\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1434 - accuracy: 0.9375 - val_loss: 1.5055 - val_accuracy: 0.8125\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2399 - accuracy: 0.9479 - val_loss: 0.3926 - val_accuracy: 0.9062\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2400 - accuracy: 0.9286 - val_loss: 0.6323 - val_accuracy: 0.8125\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.3197 - accuracy: 0.8438 - val_loss: 0.1547 - val_accuracy: 0.9375\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1980 - accuracy: 0.9062 - val_loss: 1.9727 - val_accuracy: 0.8438\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2687 - accuracy: 0.9405 - val_loss: 0.3565 - val_accuracy: 0.9062\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.3965 - accuracy: 0.9479 - val_loss: 0.6096 - val_accuracy: 0.9643\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2464 - accuracy: 0.9375 - val_loss: 0.3613 - val_accuracy: 0.9375\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1934 - accuracy: 0.8929 - val_loss: 0.2842 - val_accuracy: 0.9062\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1901 - accuracy: 0.9167 - val_loss: 0.7133 - val_accuracy: 0.8438\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2969 - accuracy: 0.9167 - val_loss: 0.0864 - val_accuracy: 0.9062\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1127 - accuracy: 0.9479 - val_loss: 0.4301 - val_accuracy: 0.9688\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1332 - accuracy: 0.9583 - val_loss: 0.6264 - val_accuracy: 0.9062\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2331 - accuracy: 0.9062 - val_loss: 1.1140 - val_accuracy: 0.8125\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.3816 - accuracy: 0.9479 - val_loss: 0.0545 - val_accuracy: 0.9375\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2008 - accuracy: 0.8958 - val_loss: 0.0601 - val_accuracy: 0.9688\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1361 - accuracy: 0.9167 - val_loss: 2.8690 - val_accuracy: 0.8438\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2759 - accuracy: 0.8929 - val_loss: 0.0593 - val_accuracy: 0.9688\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1335 - accuracy: 0.9479 - val_loss: 0.1311 - val_accuracy: 0.9688\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1858 - accuracy: 0.9375 - val_loss: 1.4145 - val_accuracy: 0.8929\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2215 - accuracy: 0.9375 - val_loss: 0.1299 - val_accuracy: 0.9375\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1310 - accuracy: 0.9524 - val_loss: 1.9536 - val_accuracy: 0.9062\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.1886 - accuracy: 0.9375 - val_loss: 1.1498 - val_accuracy: 0.8750\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.3202 - accuracy: 0.8646 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4527 - accuracy: 0.8958 - val_loss: 0.2299 - val_accuracy: 0.9688\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1867 - accuracy: 0.9167 - val_loss: 1.5089 - val_accuracy: 0.8438\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1810 - accuracy: 0.9479 - val_loss: 0.1729 - val_accuracy: 0.9688\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.3841 - accuracy: 0.9167 - val_loss: 0.6625 - val_accuracy: 0.8438\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.3723 - accuracy: 0.8333 - val_loss: 0.3539 - val_accuracy: 0.9062\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2037 - accuracy: 0.9405 - val_loss: 0.0776 - val_accuracy: 0.9688\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.3525 - accuracy: 0.8854 - val_loss: 0.9999 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2205 - accuracy: 0.9583 - val_loss: 0.2622 - val_accuracy: 0.9375\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.0680 - accuracy: 0.9896 - val_loss: 1.5507 - val_accuracy: 0.9286\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1223 - accuracy: 0.9479 - val_loss: 0.2662 - val_accuracy: 0.9375\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3357 - accuracy: 0.9167 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.3105 - accuracy: 0.9271 - val_loss: 0.4362 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1962 - accuracy: 0.9167 - val_loss: 0.9820 - val_accuracy: 0.9062\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1116 - accuracy: 0.9688 - val_loss: 0.0875 - val_accuracy: 0.9688\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.2207 - accuracy: 0.9479 - val_loss: 0.7238 - val_accuracy: 0.8750\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1619 - accuracy: 0.9286 - val_loss: 0.0857 - val_accuracy: 0.9375\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1885 - accuracy: 0.9375 - val_loss: 2.8245 - val_accuracy: 0.6562\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.4968 - accuracy: 0.9062 - val_loss: 0.0761 - val_accuracy: 0.9062\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1943 - accuracy: 0.9271 - val_loss: 0.0807 - val_accuracy: 0.9688\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2121 - accuracy: 0.9524 - val_loss: 0.1321 - val_accuracy: 0.8750\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0872 - accuracy: 0.9792 - val_loss: 0.1383 - val_accuracy: 0.9375\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.4651 - accuracy: 0.8750 - val_loss: 0.1407 - val_accuracy: 0.8929\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1648 - accuracy: 0.9167 - val_loss: 0.6155 - val_accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.1947 - accuracy: 0.9375 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.2284 - accuracy: 0.9479 - val_loss: 0.0464 - val_accuracy: 0.9375\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1504 - accuracy: 0.9688 - val_loss: 0.1966 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1714 - accuracy: 0.9286 - val_loss: 0.6565 - val_accuracy: 0.9375\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.3210 - accuracy: 0.9167 - val_loss: 0.4558 - val_accuracy: 0.8125\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1375 - accuracy: 0.9762 - val_loss: 1.3506 - val_accuracy: 0.8438\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.2646 - accuracy: 0.9167 - val_loss: 0.2751 - val_accuracy: 0.8750\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.1370 - accuracy: 0.9583 - val_loss: 2.3294 - val_accuracy: 0.9375\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1441 - accuracy: 0.9271 - val_loss: 0.7888 - val_accuracy: 0.8125\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.3759 - accuracy: 0.8750 - val_loss: 0.2770 - val_accuracy: 0.9375\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1479 - accuracy: 0.9405 - val_loss: 0.6009 - val_accuracy: 0.8750\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1151 - accuracy: 0.9583 - val_loss: 0.1498 - val_accuracy: 0.8929\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 0.0042 - val_accuracy: 0.9375\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1220 - accuracy: 0.9762 - val_loss: 0.6712 - val_accuracy: 0.9062\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.1974 - accuracy: 0.9375 - val_loss: 0.6177 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1492 - accuracy: 0.9643 - val_loss: 0.1973 - val_accuracy: 0.9375\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.2513 - accuracy: 0.9583 - val_loss: 0.6010 - val_accuracy: 0.8438\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0888 - accuracy: 0.9688 - val_loss: 0.7324 - val_accuracy: 0.8750\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2196 - accuracy: 0.9479 - val_loss: 2.0967 - val_accuracy: 0.8750\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1375 - accuracy: 0.9643 - val_loss: 0.4320 - val_accuracy: 0.9688\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.2880 - accuracy: 0.9167 - val_loss: 0.4203 - val_accuracy: 0.8438\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0762 - accuracy: 0.9688 - val_loss: 0.9332 - val_accuracy: 0.8750\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0895 - accuracy: 0.9792 - val_loss: 1.1697 - val_accuracy: 0.8750\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1748 - accuracy: 0.9271 - val_loss: 0.5090 - val_accuracy: 0.9375\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1726 - accuracy: 0.9643 - val_loss: 0.0604 - val_accuracy: 0.9643\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1271 - accuracy: 0.9479 - val_loss: 2.3766 - val_accuracy: 0.8438\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.1141 - accuracy: 0.9479 - val_loss: 1.3002 - val_accuracy: 0.8125\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1828 - accuracy: 0.9286 - val_loss: 1.2730 - val_accuracy: 0.9688\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1682 - accuracy: 0.9583 - val_loss: 0.1319 - val_accuracy: 0.8125\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.2194 - accuracy: 0.9479 - val_loss: 0.1022 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        shear_range=0.2,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator()#escale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    save_to_dir=\"../data/save/\",\n",
    "    save_prefix='test',\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights(str(save_path+model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop='../data/test/populated/IMG_0237_square_44.png'\n",
    "unpop='../data/test/unpopulated/IMG_0246_square_33.png'\n",
    "grey='../data/save/test_9_4058204.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=load_img(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F16D06A5310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_gray(image_array,bgr=False):\n",
    "    if bgr: return np.array([[0.21*image_array[i][j][2] + 0.72*image_array[i][j][1] + 0.07*image_array[i][j][0] for j in range(image_array.shape[1])]\n",
    "                            for i in range(image_array.shape[0])])\n",
    "    return np.array([[0.21*image_array[i][j][0] + 0.72*image_array[i][j][1] + 0.07*image_array[i][j][2] for j in range(image_array.shape[1])]\n",
    "                            for i in range(image_array.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=rgb_to_gray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yg=array_to_img(y.reshape(y.shape+(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yga=img_to_array(yg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.606227e-10]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(yga.reshape(1,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg=load_img(grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lga=img_to_array(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[182., 182., 182.],\n",
       "        [183., 183., 183.],\n",
       "        [180., 180., 180.],\n",
       "        ...,\n",
       "        [ 35.,  35.,  35.],\n",
       "        [ 33.,  33.,  33.],\n",
       "        [ 30.,  30.,  30.]],\n",
       "\n",
       "       [[181., 181., 181.],\n",
       "        [184., 184., 184.],\n",
       "        [182., 182., 182.],\n",
       "        ...,\n",
       "        [ 25.,  25.,  25.],\n",
       "        [ 23.,  23.,  23.],\n",
       "        [ 22.,  22.,  22.]],\n",
       "\n",
       "       [[180., 180., 180.],\n",
       "        [183., 183., 183.],\n",
       "        [182., 182., 182.],\n",
       "        ...,\n",
       "        [ 27.,  27.,  27.],\n",
       "        [ 29.,  29.,  29.],\n",
       "        [ 32.,  32.,  32.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 70.,  70.,  70.],\n",
       "        [ 61.,  61.,  61.],\n",
       "        [ 54.,  54.,  54.],\n",
       "        ...,\n",
       "        [ 39.,  39.,  39.],\n",
       "        [ 50.,  50.,  50.],\n",
       "        [ 47.,  47.,  47.]],\n",
       "\n",
       "       [[ 76.,  76.,  76.],\n",
       "        [ 65.,  65.,  65.],\n",
       "        [ 55.,  55.,  55.],\n",
       "        ...,\n",
       "        [ 34.,  34.,  34.],\n",
       "        [ 49.,  49.,  49.],\n",
       "        [ 54.,  54.,  54.]],\n",
       "\n",
       "       [[ 74.,  74.,  74.],\n",
       "        [ 74.,  74.,  74.],\n",
       "        [ 59.,  59.,  59.],\n",
       "        ...,\n",
       "        [ 31.,  31.,  31.],\n",
       "        [ 46.,  46.,  46.],\n",
       "        [ 53.,  53.,  53.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
